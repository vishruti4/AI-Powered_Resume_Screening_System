{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0548d12ecd9f450bbaba2029acb00cba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_856aa8950b5248028f4eb531efda54ae",
              "IPY_MODEL_888fe3bd7bda4babbcefb4f7e4675a78",
              "IPY_MODEL_53594fdec79b458cac724e5a02838e30"
            ],
            "layout": "IPY_MODEL_dce75303736948d99cf3712cf4a045e0"
          }
        },
        "856aa8950b5248028f4eb531efda54ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06aeea8be5ae4a90abc4318141d765b3",
            "placeholder": "​",
            "style": "IPY_MODEL_07accbb78e2f453e9e5af008d5e4cf8f",
            "value": "Batches: 100%"
          }
        },
        "888fe3bd7bda4babbcefb4f7e4675a78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b053bf9106b48fcb5360a0e576d7058",
            "max": 31,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ef069927ebe4cf199509ddf8b078b24",
            "value": 31
          }
        },
        "53594fdec79b458cac724e5a02838e30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f531a8922f724c2eb737b0b2b8e26dcf",
            "placeholder": "​",
            "style": "IPY_MODEL_673eaffd639e4c83bc9a3aee8cd6c39b",
            "value": " 31/31 [02:19&lt;00:00,  2.36s/it]"
          }
        },
        "dce75303736948d99cf3712cf4a045e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06aeea8be5ae4a90abc4318141d765b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07accbb78e2f453e9e5af008d5e4cf8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b053bf9106b48fcb5360a0e576d7058": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ef069927ebe4cf199509ddf8b078b24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f531a8922f724c2eb737b0b2b8e26dcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "673eaffd639e4c83bc9a3aee8cd6c39b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q spacy scikit-learn sentence-transformers\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "5qH0kS8mfezb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0beb8f10-2167-4830-f945-336ae7089222"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "import re\n",
        "import string\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "SUm4b0zRfmBo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/UpdatedResumeDataSet.csv')  # Update path in Colab\n",
        "df = df[['Category', 'Resume']]  # Ensure relevant columns"
      ],
      "metadata": {
        "id": "13lDwGMEfn_-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Preprocessing (spaCy)"
      ],
      "metadata": {
        "id": "AvHZ5MKXf8DF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def clean_text(text):\n",
        "    doc = nlp(text.lower())\n",
        "    tokens = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df['Cleaned_Resume'] = df['Resume'].apply(clean_text)\n"
      ],
      "metadata": {
        "id": "NRaVsMEdftkJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "_3YA9R9sjgUP",
        "outputId": "609fe106-9ee4-4491-b5ae-2cd5923f028f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Category                                             Resume  \\\n",
              "0  Data Science  Skills * Programming Languages: Python (pandas...   \n",
              "1  Data Science  Education Details \\r\\nMay 2013 to May 2017 B.E...   \n",
              "2  Data Science  Areas of Interest Deep Learning, Control Syste...   \n",
              "3  Data Science  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...   \n",
              "4  Data Science  Education Details \\r\\n MCA   YMCAUST,  Faridab...   \n",
              "5  Data Science  SKILLS C Basics, IOT, Python, MATLAB, Data Sci...   \n",
              "6  Data Science  Skills â¢ Python â¢ Tableau â¢ Data Visuali...   \n",
              "7  Data Science  Education Details \\r\\n B.Tech   Rayat and Bahr...   \n",
              "8  Data Science  Personal Skills â¢ Ability to quickly grasp t...   \n",
              "9  Data Science  Expertise â Data and Quantitative Analysis â...   \n",
              "\n",
              "                                      Cleaned_Resume  \n",
              "0  skill programming language python panda numpy ...  \n",
              "1  education detail uit rgpv data scientist data ...  \n",
              "2  area interest deep learning control system des...  \n",
              "3  skill r python sap hana tableau sap hana sql s...  \n",
              "4  education detail mca ymcaust faridabad haryana...  \n",
              "5  skill c basic iot python matlab datum science ...  \n",
              "6  skill python tableau datum visualization r stu...  \n",
              "7  education detail rayat bahra institute enginee...  \n",
              "8  personal skill ability quickly grasp technical...  \n",
              "9  expertise datum quantitative analysis decision...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e95396b-3a07-4b38-98eb-2b5491cc1fcc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Resume</th>\n",
              "      <th>Cleaned_Resume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>Skills * Programming Languages: Python (pandas...</td>\n",
              "      <td>skill programming language python panda numpy ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>Education Details \\r\\nMay 2013 to May 2017 B.E...</td>\n",
              "      <td>education detail uit rgpv data scientist data ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>Areas of Interest Deep Learning, Control Syste...</td>\n",
              "      <td>area interest deep learning control system des...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...</td>\n",
              "      <td>skill r python sap hana tableau sap hana sql s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>Education Details \\r\\n MCA   YMCAUST,  Faridab...</td>\n",
              "      <td>education detail mca ymcaust faridabad haryana...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>SKILLS C Basics, IOT, Python, MATLAB, Data Sci...</td>\n",
              "      <td>skill c basic iot python matlab datum science ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>Skills â¢ Python â¢ Tableau â¢ Data Visuali...</td>\n",
              "      <td>skill python tableau datum visualization r stu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>Education Details \\r\\n B.Tech   Rayat and Bahr...</td>\n",
              "      <td>education detail rayat bahra institute enginee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>Personal Skills â¢ Ability to quickly grasp t...</td>\n",
              "      <td>personal skill ability quickly grasp technical...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>Expertise â Data and Quantitative Analysis â...</td>\n",
              "      <td>expertise datum quantitative analysis decision...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e95396b-3a07-4b38-98eb-2b5491cc1fcc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6e95396b-3a07-4b38-98eb-2b5491cc1fcc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6e95396b-3a07-4b38-98eb-2b5491cc1fcc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b3a247b3-9483-4559-a76e-517ac5f3b1d8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b3a247b3-9483-4559-a76e-517ac5f3b1d8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b3a247b3-9483-4559-a76e-517ac5f3b1d8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 962,\n  \"fields\": [\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"Civil Engineer\",\n          \"DevOps Engineer\",\n          \"Data Science\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Resume\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 166,\n        \"samples\": [\n          \"KEY COMPETENCIES \\u00e2\\u009c\\u00b6Multi - Operations Management\\u00e2\\u009c\\u00b6People Management \\u00e2\\u009c\\u00b6Customer Services - Emails \\u00e2\\u009c\\u00b6 MIS \\u00e2\\u009c\\u00b6Vendor & Client Services Management\\u00e2\\u009c\\u00b6Cross Functional Coordination\\u00e2\\u009c\\u00b6Banking & Financial Services\\u00e2\\u009c\\u00b6 Transaction Monitoring * ATM Operations \\u00e2\\u009c\\u00b6 & Prepaid Card Operations (Pre-Issuance & Post-Issuance) \\u00e2\\u009c\\u00b6 POS Operations * JOB PROFILE & SKILLS: \\u00e2\\u0080\\u00a2 An effective communicator with excellent relationship building & interpersonal skills. Strong analytical, problem solving & organizational abilities. \\u00e2\\u0080\\u00a2 Extensive experience in managing operations with demonstrated leadership qualities & organisational skills during the tenure. \\u00e2\\u0080\\u00a2 Managing customer centric operations & ensuring customer satisfaction by achieving service quality norms. \\u00e2\\u0080\\u00a2 Analyzing of all operational problems, customer complaints and take preventive and corrective actions to resolve the same. \\u00e2\\u0080\\u00a2 Receive and respond to Key customer inquiries in an effective manner and provide relevant and timely information. \\u00e2\\u0080\\u00a2 Deft in steering banking back-end operations, analyzing risks and managing delinquencies with dexterity across applying techniques for maximizing recoveries and minimizing credit losses. \\u00e2\\u0080\\u00a2 Analyzed & identified training needs of the team members and developing, organizing and conducting training programs and manage bottom quartile team to improve their performance. \\u00e2\\u0080\\u00a2 Preparing and maintaining daily MIS reports to evaluate the performance and efficiency of the process relate to various verticals. \\u00e2\\u0080\\u00a2 Measuring the performance of the processes in terms of efficiency and effectiveness matrix and ensuring adherence to SLA. \\u00e2\\u0080\\u00a2 Major Activities Define processes for Field Services were monitored and necessary checks were executed and controlled. Also measured Vendor SLA by analyzing the TAT of vendors & the Client SLA provided to us. \\u00e2\\u0080\\u00a2 As per company procedures, handling & ensuring vendor's payment issues to be sorted out &payments are processed on quarterly basis. \\u00e2\\u0080\\u00a2 Appropriately plan and execute each skill of operations in accordance with the department's policies and procedures. \\u00e2\\u0080\\u00a2 Manage relationships with business team, software development team and other services to achieve project objectives. Different software Worked till now: - a. CTL prime - Axis Bank Credit Cards b. Insight - For POS Machine technical operations for Amex (MID & TID Generation- ATOS (Venture Infotek) c. Ticket Management System - TATA Communications Private Services Ltd (ATM - NOC Operations) d. Branch Portal (Yalamanchili Software Exports Ltd) - Prepaid Cards (SBI Bank & Zaggle Prepaid Oceans Services Ltd) Zaggle Prepaid Ocean Services Pvt Ltd Oct, 2017 to Till Date Designation: Manager - Operations (Payment Industry - Prepaid Cards - INR) Education Details \\r\\n  Commerce Mumbai, Maharashtra Mumbai University\\r\\nOperations Manager \\r\\n\\r\\nService Manager - Operations (Payment Industry - Prepaid Cards - INR & FTC)\\r\\nSkill Details \\r\\nOPERATIONS- Exprience - 73 months\\r\\nSATISFACTION- Exprience - 48 months\\r\\nTRAINING- Exprience - 24 months\\r\\nNOC- Exprience - 23 months\\r\\nPOINT OF SALE- Exprience - 20 monthsCompany Details \\r\\ncompany - Zaggle Prepaid Ocean Services Pvt Ltd\\r\\ndescription - Card Operations\\r\\ncompany - Yalamanchili Software Exports Ltd\\r\\ndescription - 24*7 Operations Pvt Ltd) Dec 2015 to Feb 2017\\r\\n\\r\\nDesignation: Service Manager - Operations (Payment Industry - Prepaid Cards - INR & FTC)\\r\\n\\r\\nKey Contributions: \\u00e2\\u0080\\u00a2 A result-oriented business professional in planning, executing& managing processes, improving efficiency of operations, team building and detailing process information to determine effective result into operations.\\r\\n\\u00e2\\u0080\\u00a2 Ensuring PINs generation (SLA) is maintained and chargeback cases are raised in perfect timeframe.\\r\\n\\u00e2\\u0080\\u00a2 Managing email customer services properly and ensuring the emails are replied properly. Also, ensuring transaction monitoring is properly managed 24/7.\\r\\n\\u00e2\\u0080\\u00a2 Assisting Bankers (SBI & Associated Banks) for their BCP plans by getting executed in the system with the help of DR-PR plans & vice versa or any other business requirements.\\r\\n\\u00e2\\u0080\\u00a2 Expertise in maintaining highest level of quality in operations; ensuring adherence to all the quality parameters and procedures as per the stringent norms.\\r\\n\\u00e2\\u0080\\u00a2 Lead, manage and supervise the execution of external audit engagements and responsible for presenting the findings & developing a quality reports to the senior Management and Clients.\\r\\n\\u00e2\\u0080\\u00a2 Coach/mentor (20) team members to perform at a higher level by giving opportunities, providing timely continuous feedback and working with staff to improve their communication, time management, decision making, organization, and analytical skills.\\r\\n\\u00e2\\u0080\\u00a2 Providing the solutions and services to the client in their own premises with aforesaid count of team members.\\r\\n\\u00e2\\u0080\\u00a2 Also ensuring end to end process of PR & DR as per client requirements (PR- DR & DR -PR) by interacting with internal & external stakeholders.\\r\\n\\u00e2\\u0080\\u00a2 Determining process gaps and designing & conducting training programs to enhance operational efficiency and retain talent by providing optimum opportunities for personal and professional growth.\\r\\ncompany - Credit Cards\\r\\ndescription - Ensured highest standard of customer satisfaction and quality service; developing new policies and procedures to improve based on customer feedback and resolving customer queries via correspondence, inbound calls & email channels with the strength of (12-16) Team members.\\r\\ncompany - AGS Transact Technologies Limited\\r\\ndescription - Key Contributions: Lead - SPOC to Banks\\r\\ncompany - TATA Communications Payment Solutions Ltd\\r\\ndescription - To make ATMs operational within TAT by analyzing the issue is technical or non-technical and also by interacting with internal & external stakeholders.\\r\\ncompany - Vertex Customer Solutions India Private Ltd\\r\\ndescription - Key Contributions: \\u00e2\\u0080\\u00a2 Build positive working relationship with all team members and clients by keeping Management informed   of KYC document collection & con-current audit progress, responding timely to Management inquiries, understanding the business and conducting self professionally.\\r\\ncompany - Financial Inclusion Network & Operations Limited\\r\\ndescription - Key Contributions: POS-Operations \\u00e2\\u0080\\u00a2 Cascading the adherence of process is strictly followed by team members & training them to reduce the downtime.\\r\\n\\u00e2\\u0080\\u00a2 Managing Stock of EDC Terminals \\u00e2\\u0080\\u00a2 Managing Deployments of terminals through Multiple teams \\u00e2\\u0080\\u00a2 Would have worked with multiple terminal make & model \\u00e2\\u0080\\u00a2 Managing Inward, Outward & QC of applications installed in the POS machines.\\r\\ncompany - Venture Infotek Private Ltd\\r\\ndescription - Key Contributions: POS-Operations\\r\\ncompany - Axis Bank Ltd - Customer Services\\r\\ndescription - Aug 2006 to Oct 2009 (Ma-Foi&I- smart)\\r\\n\\r\\nDesignation: Team Leader/Executive - Emails, Phone Banking & Correspondence Unit (Snail Mails)\",\n          \"Skill Set: Hadoop, Map Reduce, HDFS, Hive, Sqoop, java. Duration: 2016 to 2017. Role: Hadoop Developer Rplus offers an quick, simple and powerful cloud based Solution, Demand Sense to accurately predict demand for your product in all your markets which Combines Enterprise and External Data to predict demand more accurately through Uses Social Conversation and Sentiments to derive demand and Identifies significant drivers of sale out of hordes of factors that Selects the best suited model out of multiple forecasting models for each product. Responsibilities: \\u00e2\\u0080\\u00a2 Involved in deploying the product for customers, gathering requirements and algorithm optimization at backend of the product. \\u00e2\\u0080\\u00a2 Load and transform Large Datasets of structured semi structured. \\u00e2\\u0080\\u00a2 Responsible to manage data coming from different sources and application \\u00e2\\u0080\\u00a2 Supported Map Reduce Programs those are running on the cluster \\u00e2\\u0080\\u00a2 Involved in creating Hive tables, loading with data and writing hive queries which will run internally in map reduce way.Education Details \\r\\n\\r\\nHadoop Developer \\r\\n\\r\\nHadoop Developer - Braindatawire\\r\\nSkill Details \\r\\nAPACHE HADOOP HDFS- Exprience - 49 months\\r\\nAPACHE HADOOP SQOOP- Exprience - 49 months\\r\\nHadoop- Exprience - 49 months\\r\\nHADOOP- Exprience - 49 months\\r\\nHADOOP DISTRIBUTED FILE SYSTEM- Exprience - 49 monthsCompany Details \\r\\ncompany - Braindatawire\\r\\ndescription - Technical Skills:\\r\\n\\u00e2\\u0080\\u00a2   Programming: Core Java, Map Reduce, Scala\\r\\n\\u00e2\\u0080\\u00a2   Hadoop Tools: HDFS, Spark, Map Reduce, Sqoop, Hive, Hbase\\r\\n\\u00e2\\u0080\\u00a2   Database: MySQL, Oracle\\r\\n\\u00e2\\u0080\\u00a2   Scripting: Shell Scripting\\r\\n\\u00e2\\u0080\\u00a2   IDE: Eclipse\\r\\n\\u00e2\\u0080\\u00a2   Operating Systems: Linux (CentOS), Windows\\r\\n\\u00e2\\u0080\\u00a2   Source Control: Git (Github)\",\n          \"IT Skills: Area Exposure Modeling Tool: Bizagi, MS Visio Prototyping Tool: Indigo Studio. Documentation: MS Office (MS Word, MS Excel, MS Power Point) Testing Proficiency: Smoke, Sanity, Integration, Functional, Acceptance and UI Methodology implemented: Waterfall, Agile (Scrum) Database: SQL Testing Tool: HPQC Business Exposure Education Details \\r\\n Bachelor Of Computer Engineering Computer Engineering Mumbai, Maharashtra Thadomal Shahani Engineering college\\r\\n Diploma Computer Engineering Ulhasnagar, Maharashtra Institute of Technology\\r\\n Secondary School Certificate  Ulhasnagar, Maharashtra New English High School\\r\\nSenior Business Analyst - RPA \\r\\n\\r\\nSenior Business Analyst - RPA - Hexaware Technologies\\r\\nSkill Details \\r\\nDOCUMENTATION- Exprience - 47 months\\r\\nTESTING- Exprience - 29 months\\r\\nINTEGRATION- Exprience - 25 months\\r\\nINTEGRATOR- Exprience - 25 months\\r\\nPROTOTYPE- Exprience - 13 monthsCompany Details \\r\\ncompany - Hexaware Technologies\\r\\ndescription - Working as a RPA Business Analyst\\r\\ncompany - BBH- Brown Brothers Harriman & Co\\r\\ndescription - is a private bank that provides commercial banking, investment management, brokerage, and trust services to private companies and individuals. It also performs merger advisory, foreign exchange, custody services, commercial banking, and corporate financing services.\\r\\n\\r\\nResponsibilities: \\u00e2\\u0080\\u00a2 Performed Automation Assessment of various Processes and identified processes which can be candidates of RPA.\\r\\n\\u00e2\\u0080\\u00a2 Conducting Assessment that involves an initial Understanding of the Existing System, their technology, processes, Usage of the tools, Feasibility of tool with automation tool along with automation ROI analysis.\\r\\n\\u00e2\\u0080\\u00a2 Preparing the Automation Potential Sheet which describes the steps in the process, the volume and frequency of the transaction, the AHT taken by SME to perform the process and depending on the steps that could be automated, Automation potential and the manual efforts that will be saved are calculated.\\r\\nCalculating the complexity of the Process which is considered for automation and depending on all these factors Number of Bots and Number of Automation tool Licenses are determined.\\r\\n\\u00e2\\u0080\\u00a2 Implementing a Proof of Concept (POC) to Validate Feasibility by executing the selected critical use cases for conducting a POC which will helps to identify financial and operational benefits and provide recommendations regarding the actual need for complete automation.\\r\\n\\u00e2\\u0080\\u00a2 Gathering business requirements by conducting detailed interviews with business users, stakeholders, and Subject Matter Experts (SME's) \\u00e2\\u0080\\u00a2 Preparing Business Requirement Document and then converted Business requirements into Functional Requirements Specification.\\r\\n \\u00e2\\u0080\\u00a2 Constructing prototype early toward a design acceptable to the customer and feasible.\\r\\n\\u00e2\\u0080\\u00a2 Assisting in designing test plans, test scenarios and test cases for integration, regression, and user acceptance testing (UAT) to improve the overall quality of the Automation.\\r\\n\\u00e2\\u0080\\u00a2 Participating regularly in Walkthroughs and Review meetings with Project Manager, QA Engineers, and Development team.\\r\\n\\u00e2\\u0080\\u00a2 Regularly interacting with offshore and onshore development teams.\\r\\ncompany - FADV - First Advantage\\r\\ndescription - is a criminal background check company that delivers global solutions ranging from employment screenings to background checks.\\r\\nThe following are the processes which were covered:\\r\\nEmail Process, Research Process, Review Process.\\r\\n\\r\\nResponsibilities: \\u00e2\\u0080\\u00a2 Requirement Gathering through conducting Interviews & Brainstorming sessions with stakeholders \\u00e2\\u0080\\u00a2 To develop decision models and execute those rules as per the use case specifications.\\r\\n\\u00e2\\u0080\\u00a2 To Test/validate the decision models against document test data.\\r\\n\\u00e2\\u0080\\u00a2 To maintain and enhance the decision models for changes in regulations as per use case specifications.\\r\\n\\u00e2\\u0080\\u00a2 Responsible for performing the business research that will make a business growth.\\r\\n\\u00e2\\u0080\\u00a2 Developing a clear understanding of existing business functions and processes.\\r\\n\\u00e2\\u0080\\u00a2 Effectively communicate with the onsite clients for the queries, suggestions, and update.\\r\\n\\u00e2\\u0080\\u00a2 Giving suggestions to enhance the current processes.\\r\\n\\u00e2\\u0080\\u00a2 Identifying areas for process improvement.\\r\\n\\u00e2\\u0080\\u00a2 Flagging up potential problems at an early stage.\\r\\n\\u00e2\\u0080\\u00a2 Preparing PowerPoint presentations and documents for business meetings.\\r\\n\\u00e2\\u0080\\u00a2 Using any information gathered to write up detailed reports.\\r\\n\\u00e2\\u0080\\u00a2 Highlighting risks and issues that could impact project delivery.\\r\\n\\u00e2\\u0080\\u00a2 Able to work accurately.\\r\\n\\u00e2\\u0080\\u00a2 To develop and maintain documentation for internal team training and client end user operations.\\r\\n\\u00e2\\u0080\\u00a2 To work efficiently with team members and across teams.\\r\\n\\u00e2\\u0080\\u00a2 To mentor and train junior team members.\\r\\ncompany - Clinical Testing, Lab Work and Diagnostic Testing\\r\\ndescription - IQVIA provides services to its customers this includes: Clinical Testing, Lab Work and Diagnostic Testing under clinical trial. These customers need to pay to IQVIA and aging details and invoices are generated for the same.\\r\\nThe following are the processes which were covered:\\r\\n\\r\\nTracking Payments, Automated Real Time Metrics Reporting (Dashboard), Past Due Notifications, AR Statements, Credit/Rebill.\\r\\nResponsibilities: \\u00e2\\u0080\\u00a2 Conducting meetings with clients and key stakeholders to gather requirements, analyze, finalize and have formal sign-offs from approvers Gather and perform analysis of the business requirements \\u00e2\\u0080\\u00a2 Translating the business requirements into the Business Requirement Document [BRD], Functional Requirement Document [FRD].\\r\\n\\u00e2\\u0080\\u00a2 Facilitating meetings with the appropriate subject matter experts in both business and technology teams \\u00e2\\u0080\\u00a2 Coordinating with business user community for the execution of user acceptance test as well as tracking issues \\u00e2\\u0080\\u00a2 Working, collaborating and coordinating with Offshore and Onsite team members to fulfill the BA responsibilities from project initiation to Post-Implementation \\u00e2\\u0080\\u00a2 Reviewing the test scripts with business users as well as technology team. Execute test scripts with expected results for the System Integration Test (SIT) and User Acceptance Test (UAT) \\u00e2\\u0080\\u00a2 Coordinating and conducting the Production Acceptance Testing (PAT) with the business users \\u00e2\\u0080\\u00a2 Creating flow diagrams, structure charts, and other types of system or process representations \\u00e2\\u0080\\u00a2 Managing changes to requirements and baseline through a change control process \\u00e2\\u0080\\u00a2 Utilizing standard methods, design and testing tools throughout project development life cycle \\u00e2\\u0080\\u00a2 Work closely with the operational functional teams, operations management, and personnel, and various technology teams to facilitate a shared understanding of requirements and priorities across all areas\\r\\ncompany - Eduavenir IT Solution\\r\\ndescription - Project: M.B.M.S\\r\\n\\r\\nM.B.M.S. - is an Inventory management application that allows user to manage inventory details of different warehouses, having different products located at various locations and help extract what goods have been procured, sold or returned by customers. It generates automated invoicesalong withcustomized reports. It also managescustomer complaint and resolution system implementation along with automated MIS on monthly basis.Sales and forecastingis also developed on MIS System and the streamlining of process of warehousing and dispatch along with online proof of delivery management system (POD documentation) is generated.\\r\\n\\r\\nResponsibilities: \\u00e2\\u0080\\u00a2 Participate in requirement gathering discussion with client to understand the flow of business processes \\u00e2\\u0080\\u00a2 Analyze the requirements and determine the core processes, develop Process Documentation and ensure to stay up-to-date in conjunction with on-going changes \\u00e2\\u0080\\u00a2 Participate in process flow analysis and preparing BRD, SRS.\\r\\n\\u00e2\\u0080\\u00a2 Coordinating with developers, designers & operations teams for various nuances of the project, communicate the stakeholder requirements from requirement /enhancement to implementation and finally deliver the same within estimated timeframe.\\r\\n\\u00e2\\u0080\\u00a2 Support UAT by reviewing test cases, manage version control of documents, software builds.\\r\\n\\u00e2\\u0080\\u00a2 Coordinate with the stakeholders for UAT sign off and coordinate internally for production movement till Golive stage of the application.\\r\\n\\u00e2\\u0080\\u00a2 Provide demo and training to internal and end user using PowerPoint presentation.\\r\\n\\u00e2\\u0080\\u00a2 Resolving project functional &technical issues during UAT.\\r\\n\\u00e2\\u0080\\u00a2 Prioritizing the Production bugs and resolving the same within the estimated timeframe.\\r\\n\\u00e2\\u0080\\u00a2 Preparing Project Status Report and Production Bugs Status to all the stakeholders.\\r\\n\\u00e2\\u0080\\u00a2 Promoting and Networking for online trading platform.\\r\\n\\u00e2\\u0080\\u00a2 Designing query sheet for obtaining and comparison of quotes from various vendors.\\r\\n\\u00e2\\u0080\\u00a2 Development of product codes / material codes for inventory management (Master Data Management)\\r\\ncompany - CAPGEMINI Head Office\\r\\ndescription - Type: Mobile and Device Testing.       Duration: January 2014 - August 2014\\r\\n\\r\\nFollet - An application which takes an electronic request from the user for the books he requires from a particular follet store. This detailed information about books that will include the name of the book, its price, the date of the transaction and the parties involved which will then be sent to follet stores. User then create request for one or more books for a given date. This request is then processed further and user gets a mail of the date when he will be provided with that book.\\r\\n\\r\\nResponsibilities: \\u00e2\\u0080\\u00a2 Understanding the needs and business requirements.\\r\\n\\u00e2\\u0080\\u00a2 Preparing BRD, SRS by eliciting all the requirements from the client and SMEs \\u00e2\\u0080\\u00a2 Understanding the dependency of the modules in the system \\u00e2\\u0080\\u00a2 Preparation of test plan for Unit level and Integration level.\\r\\n\\u00e2\\u0080\\u00a2 Preparation and execution of test cases.\\r\\n\\u00e2\\u0080\\u00a2 Defect tracking, Issue Resolution, Risk Monitoring, Status Tracking, Reporting and Follow-up.\\r\\n\\u00e2\\u0080\\u00a2 Preparation of Test Completion report.\\r\\ncompany - CAPGEMINI Head Office\\r\\ndescription - \\r\\ncompany - CAPGEMINI Head Office\\r\\ndescription - Humana is a health care insurance project of U.S. which deals with supplying various medicines to citizens as per the doctor's reference and patient's insurance policy. This application keeps track of all the medicines user has consumed in the past and generates a patient history. A citizen is given a drug only after the doctor's reference so the doctor's information is also linked with the patient's history.\\r\\n\\r\\nResponsibilities: \\u00e2\\u0080\\u00a2 Understanding the requirements and getting clarifications from client.\\r\\n\\u00e2\\u0080\\u00a2 Involved in writing test cases based on test scenarios and execute them.\\r\\n\\u00e2\\u0080\\u00a2 Ensuring Test Coverage using Requirement Traceability Matrix (RTM) \\u00e2\\u0080\\u00a2 Preparation of Test Completion report.\\r\\ncompany - CAPGEMINI Head Office\\r\\ndescription - Testing Trends WQR (World Quality Report) is an application which allows the users to take a survey on different methods and technologies used for testing. Users can choose to answer any type of questions under three different categories. Users have a facility to search, view and export the data to excel. Also, users get daily and weekly reports through email about the new trends in testing implemented around the globe. Testing Trends WQR app is available on Android and IOS platforms.\\r\\n\\r\\nResponsibilities: \\u00e2\\u0080\\u00a2 Understanding the requirements and getting clarifications from client.\\r\\n\\u00e2\\u0080\\u00a2 Writing test cases based on test scenarios and executed them.\\r\\n\\u00e2\\u0080\\u00a2 Performing different types of testing such as Functional, Integration, System, and UAT.\\r\\n\\u00e2\\u0080\\u00a2 Defect resolution and maintenance of the application.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cleaned_Resume\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 166,\n        \"samples\": [\n          \"key competency operations management service email mis client services functional financial transaction monitor atm operation prepaid card operation pre issuance post issuance pos operation job profile skill effective communicator excellent relationship building interpersonal skill strong analytical problem solve organizational ability extensive experience manage operation demonstrate leadership quality organisational skill tenure manage customer centric operation ensure customer satisfaction achieve service quality norm analyzing operational problem customer complaint preventive corrective action resolve receive respond key customer inquiry effective manner provide relevant timely information deft steer bank end operation analyze risk managing delinquency dexterity apply technique maximize recovery minimize credit loss analyze identify training need team member develop organize conduct training program manage quartile team improve performance prepare maintain daily mis report evaluate performance efficiency process relate vertical measure performance process term efficiency effectiveness matrix ensure adherence sla major activity define process field service monitor necessary check execute control measure vendor sla analyze tat vendor client sla provide company procedure handle ensure vendor payment issue sort payment process quarterly basis appropriately plan execute skill operation accordance department policy procedure manage relationship business team software development team service achieve project objective different software work till ctl prime axis bank credit card insight pos machine technical operation amex mid tid ato venture infotek ticket management system tata communication private services ltd atm noc operation branch portal yalamanchili software exports ltd prepay card sbi bank zaggle prepaid oceans services ltd zaggle prepaid ocean services pvt ltd oct till date designation manager operation payment industry prepay card inr education detail commerce mumbai maharashtra mumbai university operation manager service manager operation payment industry prepay card inr ftc skill detail exprience month exprience month exprience month exprience month point exprience monthscompany detail company zaggle prepaid ocean services pvt ltd description card operation company yalamanchili software export ltd description operation pvt ltd dec feb designation service manager operation payment industry prepay card inr ftc key contribution result orient business professional planning execute managing process improve efficiency operation team build detail process information determine effective result operation ensure pin generation sla maintain chargeback case raise perfect timeframe manage email customer service properly ensure email reply properly ensure transaction monitoring properly manage assist banker sbi associated bank bcp plan getting execute system help dr pr plan vice versa business requirement expertise maintain high level quality operation ensure adherence quality parameter procedure stringent norm lead manage supervise execution external audit engagement responsible present finding develop quality report senior management client coach mentor team member perform high level give opportunity provide timely continuous feedback work staff improve communication time management decision making organization analytical skill provide solution service client premise aforesaid count team member ensure end end process pr dr client requirement dr dr interact internal external stakeholder determine process gap designing conduct training program enhance operational efficiency retain talent provide optimum opportunity personal professional growth company credit card description ensure high standard customer satisfaction quality service develop new policy procedure improve base customer feedback resolve customer query correspondence inbound call email channel strength team member company ags transact technology limit description key contribution lead spoc bank company tata communication payment solution ltd description atms operational tat analyze issue technical non technical interact internal external stakeholder company vertex customer solution india private ltd description key contribution build positive working relationship team member client keep management inform kyc document collection con current audit progress respond timely management inquiry understand business conduct self professionally company financial inclusion network operation limit description key contribution pos operation cascade adherence process strictly follow team member train reduce downtime manage stock edc terminal manage deployment terminal multiple team work multiple terminal model managing inward outward qc application instal pos machine company venture infotek private ltd description key contribution pos operation company axis bank ltd customer service description aug oct ma smart designation team leader executive email phone banking correspondence unit snail mail\",\n          \"skill set hadoop map reduce hdfs hive sqoop java duration role hadoop developer rplus offer quick simple powerful cloud base solution demand sense accurately predict demand product market combine enterprise external datum predict demand accurately use social conversation sentiment derive demand identify significant driver sale horde factor select well suited model multiple forecasting model product responsibility involve deploy product customer gathering requirement algorithm optimization backend product load transform large dataset structured semi structured responsible manage datum come different source application support map reduce program run cluster involve create hive table load datum write hive query run internally map reduce detail hadoop developer hadoop developer braindatawire skill detail apache hadoop exprience month apache hadoop exprience month exprience month exprience month hadoop distribute file exprience monthscompany detail company braindatawire description technical skill programming core java map reduce scala hadoop tool hdfs spark map reduce sqoop hive hbase database mysql oracle scripting shell scripting ide eclipse operating system linux centos window source control git github\",\n          \"skill area exposure modeling tool bizagi ms visio prototype tool indigo studio documentation ms office ms word ms excel ms power point testing proficiency smoke sanity integration functional acceptance ui methodology implement waterfall agile scrum database sql testing tool hpqc business exposure education detail bachelor computer engineering computer engineering mumbai maharashtra thadomal shahani engineering college diploma computer engineering ulhasnagar maharashtra institute technology secondary school certificate ulhasnagar maharashtra new english high school senior business analyst rpa senior business analyst rpa hexaware technology skill detail exprience month exprience month exprience month exprience month exprience monthscompany detail company hexaware technology description work rpa business analyst company brown brother harriman co description private bank provide commercial banking investment management brokerage trust service private company individual perform merger advisory foreign exchange custody service commercial banking corporate financing service responsibility performed automation assessment process identify process candidate rpa conducting assessment involve initial understanding exist system technology process usage tool feasibility tool automation tool automation roi analysis prepare automation potential sheet describe step process volume frequency transaction aht take sme perform process depend step automate automation potential manual effort save calculate calculate complexity process consider automation depend factor number bot number automation tool license determine implement proof concept poc validate feasibility execute select critical use case conduct poc help identify financial operational benefit provide recommendation actual need complete automation gathering business requirement conduct detailed interview business user stakeholder subject matter expert sme prepare business requirement document convert business requirement functional requirement specification construct prototype early design acceptable customer feasible assist design test plan test scenario test case integration regression user acceptance testing uat improve overall quality automation participate regularly walkthrough review meeting project manager qa engineer development team regularly interact offshore onshore development team company fadv advantage description criminal background check company deliver global solution range employment screening background check follow process cover email process research process review process responsibility requirement gathering conduct interview brainstorm session stakeholder develop decision model execute rule use case specification test validate decision model document test datum maintain enhance decision model change regulation use case specification responsible perform business research business growth develop clear understanding exist business function process effectively communicate onsite client query suggestion update give suggestion enhance current process identify area process improvement flag potential problem early stage prepare powerpoint presentation document business meeting information gather write detailed report highlight risk issue impact project delivery able work accurately develop maintain documentation internal team training client end user operation work efficiently team member team mentor train junior team member company clinical testing lab work diagnostic testing description iqvia provide service customer include clinical testing lab work diagnostic testing clinical trial customer need pay iqvia age detail invoice generate follow process cover tracking payment automate real time metric reporting dashboard past notification ar statement credit rebill responsibility conduct meeting client key stakeholder gather requirement analyze finalize formal sign off approver gather perform analysis business requirement translate business requirement business requirement document brd functional requirement document frd facilitate meeting appropriate subject matter expert business technology team coordinate business user community execution user acceptance test tracking issue work collaborate coordinate offshore onsite team member fulfill ba responsibility project initiation post implementation review test script business user technology team execute test script expect result system integration test sit user acceptance test uat coordinating conduct production acceptance testing pat business user create flow diagram structure chart type system process representation manage change requirement baseline change control process utilize standard method design testing tool project development life cycle work closely operational functional team operation management personnel technology team facilitate share understanding requirement priority area company eduavenir solution description project inventory management application allow user manage inventory detail different warehouse have different product locate location help extract good procure sell return customer generate automate invoicesalong withcustomize report managescustomer complaint resolution system implementation automate mis monthly forecastingis develop mis system streamlining process warehousing dispatch online proof delivery management system pod documentation generate responsibility participate requirement gathering discussion client understand flow business process analyze requirement determine core process develop process documentation ensure stay date conjunction go change participate process flow analysis prepare brd srs coordinating developer designer operation team nuance project communicate stakeholder requirement requirement implementation finally deliver estimate timeframe support uat review test case manage version control document software build coordinate stakeholder uat sign coordinate internally production movement till golive stage application provide demo training internal end user powerpoint presentation resolve project functional technical issue uat prioritize production bug resolve estimate timeframe prepare project status report production bug status stakeholder promote network online trading platform design query sheet obtaining comparison quote vendor development product code material code inventory management master datum management company capgemini head office description type mobile device testing duration january august follet application take electronic request user book require particular follet store detailed information book include book price date transaction party involve send follet store user create request book give date request process user get mail date provide book responsibility understand need business requirement prepare brd srs elicit requirement client sme understand dependency module system preparation test plan unit level integration level preparation execution test case defect tracking issue resolution risk monitoring status tracking report follow preparation test completion report company capgemini head office description company capgemini head office description humana health care insurance project deal supply medicine citizen doctor reference patient insurance policy application keep track medicine user consume past generate patient history citizen give drug doctor reference doctor information link patient history responsibility understand requirement get clarification client involve write test case base test scenario execute ensure test coverage requirement traceability matrix rtm preparation test completion report company capgemini head office description testing trend wqr world quality report application allow user survey different method technology testing user choose answer type question different category user facility search view export datum excel user daily weekly report email new trend testing implement globe testing trend wqr app available android ios platform responsibility understand requirement get clarification client write test case base test scenario execute perform different type testing functional integration system uat defect resolution maintenance application\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT + Cosine"
      ],
      "metadata": {
        "id": "YY2rlCj7j56e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -- BERT Embeddings\n",
        "bert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "resume_embeddings = bert_model.encode(df['Resume'].tolist(), show_progress_bar=True)"
      ],
      "metadata": {
        "id": "UR_1W_xrf9Jx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0548d12ecd9f450bbaba2029acb00cba",
            "856aa8950b5248028f4eb531efda54ae",
            "888fe3bd7bda4babbcefb4f7e4675a78",
            "53594fdec79b458cac724e5a02838e30",
            "dce75303736948d99cf3712cf4a045e0",
            "06aeea8be5ae4a90abc4318141d765b3",
            "07accbb78e2f453e9e5af008d5e4cf8f",
            "9b053bf9106b48fcb5360a0e576d7058",
            "7ef069927ebe4cf199509ddf8b078b24",
            "f531a8922f724c2eb737b0b2b8e26dcf",
            "673eaffd639e4c83bc9a3aee8cd6c39b"
          ]
        },
        "outputId": "7b58013b-d937-4c8f-d40d-36da7df297c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/31 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0548d12ecd9f450bbaba2029acb00cba"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job_description = \"We are hiring a data scientist with experience in machine learning, Python, and deep learning frameworks like TensorFlow or PyTorch.\"\n",
        "job_embedding = bert_model.encode([job_description])\n"
      ],
      "metadata": {
        "id": "7TR_fShEpQhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cosine Similarity"
      ],
      "metadata": {
        "id": "TMjeMd9ygIil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "similarities = cosine_similarity(job_embedding, resume_embeddings).flatten()\n",
        "df['Similarity'] = similarities\n",
        "\n",
        "# Sort by similarity descending\n",
        "ranked_resumes = df.sort_values(by='Similarity', ascending=False).reset_index(drop=True)\n",
        "\n",
        "# Display Top N Candidates\n",
        "top_n = 10\n",
        "print(f\"\\nTop {top_n} Candidates Matching the Job Description:\\n\")\n",
        "for idx, row in ranked_resumes.head(top_n).iterrows():\n",
        "    print(f\"Rank {idx+1}:\")\n",
        "    print(f\"Category     : {row['Category']}\")\n",
        "    print(f\"Match Score  : {round(row['Similarity'], 4)}\")\n",
        "    print(f\"Resume Snippet: {row['Resume'][:300]}...\")\n",
        "    print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8LyMqTvpUDU",
        "outputId": "2aca1585-6aa0-4902-d247-45128337be08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 Candidates Matching the Job Description:\n",
            "\n",
            "Rank 1:\n",
            "Category     : Data Science\n",
            "Match Score  : 0.5867\n",
            "Resume Snippet: Skills * Programming Languages: Python (pandas, numpy, scipy, scikit-learn, matplotlib), Sql, Java, JavaScript/JQuery. * Machine learning: Regression, SVM, NaÃ¯ve Bayes, KNN, Random Forest, Decision Trees, Boosting techniques, Cluster Analysis, Word Embedding, Sentiment Analysis, Natural Language pr...\n",
            "================================================================================\n",
            "Rank 2:\n",
            "Category     : Data Science\n",
            "Match Score  : 0.5867\n",
            "Resume Snippet: Skills * Programming Languages: Python (pandas, numpy, scipy, scikit-learn, matplotlib), Sql, Java, JavaScript/JQuery. * Machine learning: Regression, SVM, NaÃ¯ve Bayes, KNN, Random Forest, Decision Trees, Boosting techniques, Cluster Analysis, Word Embedding, Sentiment Analysis, Natural Language pr...\n",
            "================================================================================\n",
            "Rank 3:\n",
            "Category     : Data Science\n",
            "Match Score  : 0.5867\n",
            "Resume Snippet: Skills * Programming Languages: Python (pandas, numpy, scipy, scikit-learn, matplotlib), Sql, Java, JavaScript/JQuery. * Machine learning: Regression, SVM, NaÃ¯ve Bayes, KNN, Random Forest, Decision Trees, Boosting techniques, Cluster Analysis, Word Embedding, Sentiment Analysis, Natural Language pr...\n",
            "================================================================================\n",
            "Rank 4:\n",
            "Category     : Data Science\n",
            "Match Score  : 0.5867\n",
            "Resume Snippet: Skills * Programming Languages: Python (pandas, numpy, scipy, scikit-learn, matplotlib), Sql, Java, JavaScript/JQuery. * Machine learning: Regression, SVM, NaÃ¯ve Bayes, KNN, Random Forest, Decision Trees, Boosting techniques, Cluster Analysis, Word Embedding, Sentiment Analysis, Natural Language pr...\n",
            "================================================================================\n",
            "Rank 5:\n",
            "Category     : Data Science\n",
            "Match Score  : 0.5599\n",
            "Resume Snippet: Education Details \r\n",
            " B.Tech   Rayat and Bahra Institute of Engineering and Biotechnology\r\n",
            "Data Science \r\n",
            "\r\n",
            "Data Science\r\n",
            "Skill Details \r\n",
            "Numpy- Exprience - Less than 1 year months\r\n",
            "Machine Learning- Exprience - Less than 1 year months\r\n",
            "Tensorflow- Exprience - Less than 1 year months\r\n",
            "Scikit- Exprien...\n",
            "================================================================================\n",
            "Rank 6:\n",
            "Category     : Data Science\n",
            "Match Score  : 0.5599\n",
            "Resume Snippet: Education Details \r\n",
            " B.Tech   Rayat and Bahra Institute of Engineering and Biotechnology\r\n",
            "Data Science \r\n",
            "\r\n",
            "Data Science\r\n",
            "Skill Details \r\n",
            "Numpy- Exprience - Less than 1 year months\r\n",
            "Machine Learning- Exprience - Less than 1 year months\r\n",
            "Tensorflow- Exprience - Less than 1 year months\r\n",
            "Scikit- Exprien...\n",
            "================================================================================\n",
            "Rank 7:\n",
            "Category     : Data Science\n",
            "Match Score  : 0.5599\n",
            "Resume Snippet: Education Details \r\n",
            " B.Tech   Rayat and Bahra Institute of Engineering and Biotechnology\r\n",
            "Data Science \r\n",
            "\r\n",
            "Data Science\r\n",
            "Skill Details \r\n",
            "Numpy- Exprience - Less than 1 year months\r\n",
            "Machine Learning- Exprience - Less than 1 year months\r\n",
            "Tensorflow- Exprience - Less than 1 year months\r\n",
            "Scikit- Exprien...\n",
            "================================================================================\n",
            "Rank 8:\n",
            "Category     : Data Science\n",
            "Match Score  : 0.5599\n",
            "Resume Snippet: Education Details \r\n",
            " B.Tech   Rayat and Bahra Institute of Engineering and Biotechnology\r\n",
            "Data Science \r\n",
            "\r\n",
            "Data Science\r\n",
            "Skill Details \r\n",
            "Numpy- Exprience - Less than 1 year months\r\n",
            "Machine Learning- Exprience - Less than 1 year months\r\n",
            "Tensorflow- Exprience - Less than 1 year months\r\n",
            "Scikit- Exprien...\n",
            "================================================================================\n",
            "Rank 9:\n",
            "Category     : Data Science\n",
            "Match Score  : 0.5055\n",
            "Resume Snippet: Personal Skills â¢ Ability to quickly grasp technical aspects and willingness to learn â¢ High energy levels & Result oriented. Education Details \r\n",
            "January 2018 Master of Engineering Computer Technology & Application Bhopal, Madhya Pradesh Truba Institute of Engineering & Information Technology\r\n",
            "J...\n",
            "================================================================================\n",
            "Rank 10:\n",
            "Category     : Data Science\n",
            "Match Score  : 0.5055\n",
            "Resume Snippet: Personal Skills â¢ Ability to quickly grasp technical aspects and willingness to learn â¢ High energy levels & Result oriented. Education Details \r\n",
            "January 2018 Master of Engineering Computer Technology & Application Bhopal, Madhya Pradesh Truba Institute of Engineering & Information Technology\r\n",
            "J...\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above output we can observe that BERT gives better accuracy than TFIDF"
      ],
      "metadata": {
        "id": "wVum1c0nlfTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the resume embeddings to disk\n",
        "with open('final_resume_embeddings.pkl', 'wb') as f:\n",
        "    pickle.dump(resume_embeddings, f)\n"
      ],
      "metadata": {
        "id": "wR_6rOemqpbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"cleaned_resumes_with_similarity.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "M_GkrdItqqW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF + Cosine Similarity"
      ],
      "metadata": {
        "id": "Q5iON4Zwj2op"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Clean resumes using spaCy\n",
        "# df['Cleaned_Resume'] = df['Resume'].apply(clean_text)\n",
        "\n",
        "# Fit TF-IDF vectorizer on resumes\n",
        "tfidf = TfidfVectorizer(max_features=1000)\n",
        "resume_tfidf = tfidf.fit_transform(df['Cleaned_Resume'])\n",
        "\n",
        "# Define and clean job description\n",
        "job_description = \"We are hiring a data scientist with experience in machine learning, Python, and deep learning frameworks like TensorFlow or PyTorch.\"\n",
        "job_desc_cleaned = clean_text(job_description)\n",
        "\n",
        "# Transform job description into TF-IDF vector\n",
        "job_tfidf = tfidf.transform([job_desc_cleaned])\n",
        "\n",
        "# Compute cosine similarity between job description and resumes\n",
        "similarities_tfidf = cosine_similarity(job_tfidf, resume_tfidf).flatten()\n",
        "df['Similarity_TFIDF'] = similarities_tfidf\n",
        "\n",
        "# Rank resumes by similarity\n",
        "ranked_tfidf = df.sort_values(by='Similarity_TFIDF', ascending=False).reset_index(drop=True)\n",
        "\n",
        "# Display Top 5 TF-IDF matches\n",
        "print(\"\\nTop 5 Candidates (TF-IDF Matching):\\n\")\n",
        "for i, row in ranked_tfidf.head(10).iterrows():\n",
        "    print(f\"Rank {i+1}:\")\n",
        "    print(f\"Category     : {row['Category']}\")\n",
        "    print(f\"Match Score  : {round(row['Similarity_TFIDF'], 4)}\")\n",
        "    print(f\"Resume Snippet: {row['Resume'][:300]}...\")\n",
        "    print(\"=\" * 80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCXeEoYCj1Xt",
        "outputId": "1ca4905d-a351-4cbe-a6e3-7d0828d91b14"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 5 Candidates (TF-IDF Matching):\n",
            "\n",
            "Rank 1:\n",
            "Category     : Data Science\n",
            "Match Score  : 0.6048\n",
            "Resume Snippet: Education Details \r\n",
            " B.Tech   Rayat and Bahra Institute of Engineering and Biotechnology\r\n",
            "Data Science \r\n",
            "\r\n",
            "Data Science\r\n",
            "Skill Details \r\n",
            "Numpy- Exprience - Less than 1 year months\r\n",
            "Machine Learning- Exprience - Less than 1 year months\r\n",
            "Tensorflow- Exprience - Less than 1 year months\r\n",
            "Scikit- Exprien...\n",
            "================================================================================\n",
            "Rank 2:\n",
            "Category     : Data Science\n",
            "Match Score  : 0.6048\n",
            "Resume Snippet: Education Details \r\n",
            " B.Tech   Rayat and Bahra Institute of Engineering and Biotechnology\r\n",
            "Data Science \r\n",
            "\r\n",
            "Data Science\r\n",
            "Skill Details \r\n",
            "Numpy- Exprience - Less than 1 year months\r\n",
            "Machine Learning- Exprience - Less than 1 year months\r\n",
            "Tensorflow- Exprience - Less than 1 year months\r\n",
            "Scikit- Exprien...\n",
            "================================================================================\n",
            "Rank 3:\n",
            "Category     : Data Science\n",
            "Match Score  : 0.6048\n",
            "Resume Snippet: Education Details \r\n",
            " B.Tech   Rayat and Bahra Institute of Engineering and Biotechnology\r\n",
            "Data Science \r\n",
            "\r\n",
            "Data Science\r\n",
            "Skill Details \r\n",
            "Numpy- Exprience - Less than 1 year months\r\n",
            "Machine Learning- Exprience - Less than 1 year months\r\n",
            "Tensorflow- Exprience - Less than 1 year months\r\n",
            "Scikit- Exprien...\n",
            "================================================================================\n",
            "Rank 4:\n",
            "Category     : Data Science\n",
            "Match Score  : 0.6048\n",
            "Resume Snippet: Education Details \r\n",
            " B.Tech   Rayat and Bahra Institute of Engineering and Biotechnology\r\n",
            "Data Science \r\n",
            "\r\n",
            "Data Science\r\n",
            "Skill Details \r\n",
            "Numpy- Exprience - Less than 1 year months\r\n",
            "Machine Learning- Exprience - Less than 1 year months\r\n",
            "Tensorflow- Exprience - Less than 1 year months\r\n",
            "Scikit- Exprien...\n",
            "================================================================================\n",
            "Rank 5:\n",
            "Category     : Data Science\n",
            "Match Score  : 0.5502\n",
            "Resume Snippet: Personal Skills â¢ Ability to quickly grasp technical aspects and willingness to learn â¢ High energy levels & Result oriented. Education Details \r\n",
            "January 2018 Master of Engineering Computer Technology & Application Bhopal, Madhya Pradesh Truba Institute of Engineering & Information Technology\r\n",
            "J...\n",
            "================================================================================\n",
            "Rank 6:\n",
            "Category     : Data Science\n",
            "Match Score  : 0.5502\n",
            "Resume Snippet: Personal Skills â¢ Ability to quickly grasp technical aspects and willingness to learn â¢ High energy levels & Result oriented. Education Details \r\n",
            "January 2018 Master of Engineering Computer Technology & Application Bhopal, Madhya Pradesh Truba Institute of Engineering & Information Technology\r\n",
            "J...\n",
            "================================================================================\n",
            "Rank 7:\n",
            "Category     : Data Science\n",
            "Match Score  : 0.5502\n",
            "Resume Snippet: Personal Skills â¢ Ability to quickly grasp technical aspects and willingness to learn â¢ High energy levels & Result oriented. Education Details \r\n",
            "January 2018 Master of Engineering Computer Technology & Application Bhopal, Madhya Pradesh Truba Institute of Engineering & Information Technology\r\n",
            "J...\n",
            "================================================================================\n",
            "Rank 8:\n",
            "Category     : Data Science\n",
            "Match Score  : 0.5502\n",
            "Resume Snippet: Personal Skills â¢ Ability to quickly grasp technical aspects and willingness to learn â¢ High energy levels & Result oriented. Education Details \r\n",
            "January 2018 Master of Engineering Computer Technology & Application Bhopal, Madhya Pradesh Truba Institute of Engineering & Information Technology\r\n",
            "J...\n",
            "================================================================================\n",
            "Rank 9:\n",
            "Category     : Data Science\n",
            "Match Score  : 0.2572\n",
            "Resume Snippet: Skills â¢ Python â¢ Tableau â¢ Data Visualization â¢ R Studio â¢ Machine Learning â¢ Statistics IABAC Certified Data Scientist with versatile experience over 1+ years in managing business, data science consulting and leading innovation projects, bringing business ideas to working real world so...\n",
            "================================================================================\n",
            "Rank 10:\n",
            "Category     : Data Science\n",
            "Match Score  : 0.2572\n",
            "Resume Snippet: Skills â¢ Python â¢ Tableau â¢ Data Visualization â¢ R Studio â¢ Machine Learning â¢ Statistics IABAC Certified Data Scientist with versatile experience over 1+ years in managing business, data science consulting and leading innovation projects, bringing business ideas to working real world so...\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Save the trained TF-IDF vectorizer\n",
        "joblib.dump(tfidf, 'tfidf_vectorizer.pkl')\n"
      ],
      "metadata": {
        "id": "xT31DPnI3xH2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2Vec / GloVe + Average Embedding + Cosine Similarity"
      ],
      "metadata": {
        "id": "NIsalEZlvxJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKpHfHhpv5FL",
        "outputId": "8fa102b8-03e0-4346-8e4c-ee9cb694d18b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install numpy==1.23.5 gensim --upgrade --force-reinstall\n"
      ],
      "metadata": {
        "id": "ebW3i30eyW60"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import gensim.downloader as api\n",
        "\n",
        "# Load pre-trained word embeddings (e.g., GloVe)\n",
        "w2v_model = api.load(\"glove-wiki-gigaword-100\")  # Or try word2vec-google-news-300\n"
      ],
      "metadata": {
        "id": "PQMtnxgozPnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_avg_embedding(text):\n",
        "    words = clean_text(text).split()\n",
        "    valid_words = [w for w in words if w in w2v_model]\n",
        "    if not valid_words:\n",
        "        return np.zeros(100)\n",
        "    return np.mean([w2v_model[w] for w in valid_words], axis=0)\n",
        "\n",
        "resume_avg_vecs = np.array([get_avg_embedding(r) for r in df['Resume']])\n",
        "\n",
        "# Step 4: Job Description\n",
        "job_description = \"We are hiring a data scientist with experience in machine learning, Python, and deep learning frameworks like TensorFlow or PyTorch.\"\n",
        "job_vec_avg = get_avg_embedding(job_description).reshape(1, -1)\n",
        "\n",
        "# Step 5: Cosine Similarity & Ranking\n",
        "similarities_avg = cosine_similarity(job_vec_avg, resume_avg_vecs).flatten()\n",
        "df['Similarity_AvgW2V'] = similarities_avg\n",
        "\n",
        "ranked_avg = df.sort_values(by='Similarity_AvgW2V', ascending=False).reset_index(drop=True)\n",
        "\n",
        "# Step 6: Display Top 10 Matches\n",
        "print(\"\\nTop 10 Candidates (Avg GloVe Embedding):\\n\")\n",
        "for i, row in ranked_avg.head(10).iterrows():\n",
        "    print(f\"Rank {i+1}:\")\n",
        "    print(f\"Category     : {row['Category']}\")\n",
        "    print(f\"Match Score  : {round(row['Similarity_AvgW2V'], 4)}\")\n",
        "    print(f\"Resume Snippet: {row['Resume'][:300]}...\")\n",
        "    print(\"=\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTLlXTyVvyDp",
        "outputId": "1aa3b761-d045-4b9b-d809-2d22191915d7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 Candidates (Avg GloVe Embedding):\n",
            "\n",
            "Rank 1:\n",
            "Category     : Data Science\n",
            "Match Score  : 0.9512\n",
            "Resume Snippet: Education Details \r\n",
            " B.Tech   Rayat and Bahra Institute of Engineering and Biotechnology\r\n",
            "Data Science \r\n",
            "\r\n",
            "Data Science\r\n",
            "Skill Details \r\n",
            "Numpy- Exprience - Less than 1 year months\r\n",
            "Machine Learning- Exprience - Less than 1 year months\r\n",
            "Tensorflow- Exprience - Less than 1 year months\r\n",
            "Scikit- Exprien...\n",
            "================================================================================\n",
            "Rank 2:\n",
            "Category     : Data Science\n",
            "Match Score  : 0.9512\n",
            "Resume Snippet: Education Details \r\n",
            " B.Tech   Rayat and Bahra Institute of Engineering and Biotechnology\r\n",
            "Data Science \r\n",
            "\r\n",
            "Data Science\r\n",
            "Skill Details \r\n",
            "Numpy- Exprience - Less than 1 year months\r\n",
            "Machine Learning- Exprience - Less than 1 year months\r\n",
            "Tensorflow- Exprience - Less than 1 year months\r\n",
            "Scikit- Exprien...\n",
            "================================================================================\n",
            "Rank 3:\n",
            "Category     : Data Science\n",
            "Match Score  : 0.9512\n",
            "Resume Snippet: Education Details \r\n",
            " B.Tech   Rayat and Bahra Institute of Engineering and Biotechnology\r\n",
            "Data Science \r\n",
            "\r\n",
            "Data Science\r\n",
            "Skill Details \r\n",
            "Numpy- Exprience - Less than 1 year months\r\n",
            "Machine Learning- Exprience - Less than 1 year months\r\n",
            "Tensorflow- Exprience - Less than 1 year months\r\n",
            "Scikit- Exprien...\n",
            "================================================================================\n",
            "Rank 4:\n",
            "Category     : Data Science\n",
            "Match Score  : 0.9512\n",
            "Resume Snippet: Education Details \r\n",
            " B.Tech   Rayat and Bahra Institute of Engineering and Biotechnology\r\n",
            "Data Science \r\n",
            "\r\n",
            "Data Science\r\n",
            "Skill Details \r\n",
            "Numpy- Exprience - Less than 1 year months\r\n",
            "Machine Learning- Exprience - Less than 1 year months\r\n",
            "Tensorflow- Exprience - Less than 1 year months\r\n",
            "Scikit- Exprien...\n",
            "================================================================================\n",
            "Rank 5:\n",
            "Category     : Data Science\n",
            "Match Score  : 0.9444\n",
            "Resume Snippet: Personal Skills â¢ Ability to quickly grasp technical aspects and willingness to learn â¢ High energy levels & Result oriented. Education Details \r\n",
            "January 2018 Master of Engineering Computer Technology & Application Bhopal, Madhya Pradesh Truba Institute of Engineering & Information Technology\r\n",
            "J...\n",
            "================================================================================\n",
            "Rank 6:\n",
            "Category     : Data Science\n",
            "Match Score  : 0.9444\n",
            "Resume Snippet: Personal Skills â¢ Ability to quickly grasp technical aspects and willingness to learn â¢ High energy levels & Result oriented. Education Details \r\n",
            "January 2018 Master of Engineering Computer Technology & Application Bhopal, Madhya Pradesh Truba Institute of Engineering & Information Technology\r\n",
            "J...\n",
            "================================================================================\n",
            "Rank 7:\n",
            "Category     : Data Science\n",
            "Match Score  : 0.9444\n",
            "Resume Snippet: Personal Skills â¢ Ability to quickly grasp technical aspects and willingness to learn â¢ High energy levels & Result oriented. Education Details \r\n",
            "January 2018 Master of Engineering Computer Technology & Application Bhopal, Madhya Pradesh Truba Institute of Engineering & Information Technology\r\n",
            "J...\n",
            "================================================================================\n",
            "Rank 8:\n",
            "Category     : Data Science\n",
            "Match Score  : 0.9444\n",
            "Resume Snippet: Personal Skills â¢ Ability to quickly grasp technical aspects and willingness to learn â¢ High energy levels & Result oriented. Education Details \r\n",
            "January 2018 Master of Engineering Computer Technology & Application Bhopal, Madhya Pradesh Truba Institute of Engineering & Information Technology\r\n",
            "J...\n",
            "================================================================================\n",
            "Rank 9:\n",
            "Category     : HR\n",
            "Match Score  : 0.9315\n",
            "Resume Snippet: SOFTWARE SKILLS: â¢ General Computer Proficiency â¢ Program Langages known C, C+, Java, Web Programming â¢ Tools & Software know MATLAB. DBMS KEY STRENGTHS: â¢ Posse's Good communication and analytic skills. â¢ Positive thinking. Sincere, Hard work, Honesty, Responsibility. â¢ Enthusiastic to ...\n",
            "================================================================================\n",
            "Rank 10:\n",
            "Category     : HR\n",
            "Match Score  : 0.9315\n",
            "Resume Snippet: SOFTWARE SKILLS: â¢ General Computer Proficiency â¢ Program Langages known C, C+, Java, Web Programming â¢ Tools & Software know MATLAB. DBMS KEY STRENGTHS: â¢ Posse's Good communication and analytic skills. â¢ Positive thinking. Sincere, Hard work, Honesty, Responsibility. â¢ Enthusiastic to ...\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Save the word embedding model (Word2Vec or GloVe)\n",
        "w2v_model.save(\"w2v_model.model\")  # Works if it's a gensim model\n",
        "\n",
        "# Save the resume vectors (numpy array)\n",
        "np.save(\"resume_avg_embeddings.npy\", resume_avg_vecs)\n",
        "\n"
      ],
      "metadata": {
        "id": "chyPfI2U4AUM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Accept PDF resumes from frontend\n",
        "Your frontend should send user-uploaded PDF files (via form/file upload) to your backend API (e.g., Flask, FastAPI, Node.js).\n",
        "\n",
        "2. Extract text from PDF resumes\n",
        "On the backend, before matching, you must extract the raw text from PDFs using a library such as:\n",
        "\n",
        "# For Python backend\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "def extract_text_from_pdf(file_path):\n",
        "    reader = PdfReader(file_path)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text() or \"\"\n",
        "    return text\n",
        "    \n",
        "Alternatives:\n",
        "\n",
        "pdfplumber – better layout handling\n",
        "\n",
        "pdfminer.six – more control over structured extraction\n",
        "\n",
        "3. Clean and preprocess the extracted text\n",
        "You must use the same clean_text() function that you used during training (with spaCy tokenization and lemmatization). This ensures consistent feature representation.\n",
        "\n",
        "python\n",
        "\n",
        "resume_text = extract_text_from_pdf(\"user_resume.pdf\")\n",
        "cleaned_resume = clean_text(resume_text)\n",
        "\n",
        "4. Convert to embedding or vector\n",
        "Depending on your model:\n",
        "\n",
        "TF-IDF:\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "resume_vector = tfidf_vectorizer.transform([cleaned_resume])\n",
        "BERT:\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "resume_vector = bert_model.encode([resume_text])\n",
        "GloVe (Avg Embeddings):\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "resume_vector = get_avg_embedding(resume_text).reshape(1, -1)\n",
        "\n",
        "5. Match with Job Description\n",
        "Preprocess the job description the same way\n",
        "\n",
        "Compute cosine similarity\n",
        "\n",
        "Return top-N match score or ranking\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "score = cosine_similarity(job_vector, resume_vector).flatten()[0]\n"
      ],
      "metadata": {
        "id": "pmHzmCqX2lA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For Python backend\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "def extract_text_from_pdf(file_path):\n",
        "    reader = PdfReader(file_path)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text() or \"\"\n",
        "    return text\n",
        "\n",
        "resume_text = extract_text_from_pdf(\"user_resume.pdf\")\n",
        "cleaned_resume = clean_text(resume_text)\n",
        "\n",
        "resume_vector = tfidf_vectorizer.transform([cleaned_resume])\n",
        "\n",
        "resume_vector = bert_model.encode([resume_text])\n",
        "\n",
        "resume_vector = get_avg_embedding(resume_text).reshape(1, -1)\n"
      ],
      "metadata": {
        "id": "Lne2nSL23JlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Frontend PDF Upload] → [Backend]\n",
        "\n",
        " → Extract Text (PyPDF2/pdfplumber)\n",
        "\n",
        " → Clean + Preprocess\n",
        "\n",
        " → Convert to Feature Vector (TF-IDF/BERT)\n",
        "\n",
        " → Compare with Job Description\n",
        "\n",
        " → Return Similarity Score / Rank\n"
      ],
      "metadata": {
        "id": "Dfqy3nEt3Xb1"
      }
    }
  ]
}